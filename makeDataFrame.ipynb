{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc86f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import request\n",
    "from requests.compat import *\n",
    "from bs4 import BeautifulSoup\n",
    "from user_agent import generate_user_agent\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "def CrawlCategoryId(category_id, filename='categoryId.csv'):\n",
    "    url = 'https://search.shopping.naver.com/search/category/' \n",
    "    headers = {'User-Agent': 'Yeti',}\n",
    "    params = {\n",
    "        'pagingIndex' : '1',\n",
    "        'pagingSize' : '80',\n",
    "        'productSet' : 'model'\n",
    "    }\n",
    "    resp = request('GET',url=url+str(category_id), headers=headers)\n",
    "    print(resp.request.url)\n",
    "\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    script_tag = dom.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "    data = json.loads(script_tag.text)\n",
    "\n",
    "    title_value_pairs = [{'title': x['title'], 'value': x['value']} for x in data['props']['pageProps']['initialState']['mainFilters'][0]['filterValues']]\n",
    "    category_df = pd.DataFrame(title_value_pairs)\n",
    "\n",
    "    rows_to_drop = []\n",
    "    rows_to_append = []\n",
    "\n",
    "    for index, row in category_df.iterrows():\n",
    "        category_url = url + str(row['value'])\n",
    "        time.sleep(0.3)\n",
    "        resp = request('GET',url=category_url,params=params, headers=headers)\n",
    "        print(resp.request.url)\n",
    "        dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "        script_tag = dom.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "        data = json.loads(script_tag.text)\n",
    "\n",
    "        if data['props']['pageProps']['initialState']['subFilters']:\n",
    "            product_count = data['props']['pageProps']['initialState']['subFilters'][0]['filterValues'][1]['productCount']\n",
    "        else:\n",
    "            product_count = 0\n",
    "\n",
    "        if int(product_count)/int(params['pagingSize']) > 100:\n",
    "            print(row['title'], row['value'], product_count, product_count/int(params['pagingSize']))\n",
    "            rows_to_drop.append(index)\n",
    "            sub_title_value_pairs = [{'title': x['title'], 'value': x['value']} for x in data['props']['pageProps']['initialState']['mainFilters'][0]['filterValues']]\n",
    "            rows_to_append += sub_title_value_pairs\n",
    "\n",
    "    # Drop the rows from original DataFrame\n",
    "    category_df = category_df.drop(rows_to_drop)\n",
    "\n",
    "    # Append new rows to DataFrame\n",
    "    category_df = category_df.append(rows_to_append, ignore_index=True)\n",
    "\n",
    "    category_df.to_csv(filename, index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accafd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePageDF(category_id, page_id):\n",
    "    url = 'https://search.shopping.naver.com/search/category/' + str(category_id)\n",
    "    params = {\n",
    "        'pagingIndex' : str(page_id),\n",
    "        'pagingSize' : '80',\n",
    "        'productSet' : 'model'\n",
    "    }\n",
    "    headers = {'User-Agent': 'Yeti',}\n",
    "    resp = request('GET',url=url, params=params, headers=headers)\n",
    "    print(resp.request.url)\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    script_tag = dom.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "    data = json.loads(script_tag.text)\n",
    "    itemList = data['props']['pageProps']['initialState']['products']\n",
    "    \n",
    "    \n",
    "    # 각 상품의 정보를 저장할 리스트를 생성합니다.\n",
    "    products_info = []\n",
    "\n",
    "    for item in itemList['list'][:80]:\n",
    "\n",
    "        attributes_dict = dict()\n",
    "        # 'attributeValue'와 'characterValue' 문자열을 리스트로 분리합니다.\n",
    "        attribute_values = item['item'].get('attributeValue','').split('|')\n",
    "        character_values = item['item'].get('characterValue','').split('|')\n",
    "\n",
    "        # 'attributeValue' 리스트의 각 요소에서 '_M' 문자열을 제거합니다.\n",
    "        attribute_values = [value.replace('_M', '') for value in attribute_values]\n",
    "\n",
    "        min_len = min(len(attribute_values), len(character_values))\n",
    "\n",
    "        for j in range(min_len):\n",
    "            attribute = attribute_values[j]\n",
    "            character = character_values[j]\n",
    "\n",
    "            if attribute in attributes_dict:\n",
    "                attributes_dict[attribute].append(character)\n",
    "            else:\n",
    "                attributes_dict[attribute] = [character]\n",
    "\n",
    "        attribute_list = [item['item']['category3Name']]\n",
    "\n",
    "        for i in attributes_dict:\n",
    "            if i not in ['용량', '구성', '']:\n",
    "                attribute_list = attribute_list + attributes_dict[i]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        dict_data = {\n",
    "            'ID': item['item']['id'],\n",
    "            '상품명': item['item']['productName'],\n",
    "            '상품 카테고리 대분류': item['item']['category1Name'],\n",
    "            '상품 카테고리 중분류': item['item']['category2Name'],\n",
    "            '상품 카테고리 소분류': item['item']['category3Name'],\n",
    "            '제조사': item['item'].get('maker',''),\n",
    "            '브랜드': item['item'].get('brand',''),\n",
    "            '특징': attribute_list\n",
    "        }\n",
    "        for attribute in attribute_list:\n",
    "            dict_data[attribute] = True\n",
    "\n",
    "        products_info.append(dict_data)\n",
    "\n",
    "    total = data['props']['pageProps']['initialState']['products']['total']\n",
    "    total_page = math.ceil(total/int(params['pagingSize']))\n",
    "        \n",
    "        # 딕셔너리의 리스트를 데이터프레임으로 변환합니다.\n",
    "    df = pd.DataFrame(products_info)\n",
    "    \n",
    "    return df,total_page\n",
    "\n",
    "def makeCategoryDF(category_id):\n",
    "\n",
    "    \n",
    "    df,total_page = makePageDF(category_id,1)\n",
    "        \n",
    "    if total_page >1:\n",
    "        for i in range(2,total_page+1):\n",
    "            new_df, _ = makePageDF(category_id,i)\n",
    "            time.sleep(0.3)\n",
    "            df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    df = df.drop_duplicates(subset=['ID'])\n",
    "\n",
    "    df = pd.DataFrame(df).astype({'제조사': 'category'})\n",
    "    df = pd.DataFrame(df).astype({'브랜드': 'category'})\n",
    "\n",
    "    attribute_columns = df.columns.drop(['ID', '상품명', '상품 카테고리 대분류', '상품 카테고리 중분류','상품 카테고리 소분류','제조사','브랜드','특징'])\n",
    "    df[attribute_columns] = df[attribute_columns].fillna(False).astype('bool')\n",
    "    \n",
    "    small_df = df.explode('특징')[['ID','상품명','특징']]\n",
    "    attributes = pd.DataFrame(small_df['특징'].unique()).reset_index()\n",
    "    attributes.columns = ['attribute_id', '특징']\n",
    "    attributes = pd.DataFrame(attributes).astype({'attribute_id': 'category'})\n",
    "    merged_df = pd.merge(small_df, attributes, on=['특징'])\n",
    "    \n",
    "    return df, merged_df, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_category_data():\n",
    "    df_total = pd.DataFrame()\n",
    "    merged_df_total = pd.DataFrame()\n",
    "    attributes_total = pd.DataFrame()\n",
    "\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv('categoryId.csv')\n",
    "\n",
    "    # 'value' 열의 값들을 리스트로 변환\n",
    "    category_ids = df['value'].values.tolist()\n",
    "\n",
    "    for category_id in category_ids: # 여기서 category_ids는 여러분이 반복하고자 하는 카테고리 ID들의 리스트입니다.\n",
    "        df, merged_df, attributes = makeCategoryDF(category_id)\n",
    "        df_total = pd.concat([df_total, df])\n",
    "        merged_df_total = pd.concat([merged_df_total, merged_df])\n",
    "        attributes_total = pd.concat([attributes_total, attributes])\n",
    "\n",
    "    # 이제 df_total, merged_df_total, attributes_total는 모든 카테고리에 대한 데이터를 포함하고 있습니다.\n",
    "    return df_total, merged_df_total, attributes_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c93ea774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.shopping.naver.com/search/category/100000003\n",
      "https://search.shopping.naver.com/search/category/100008810?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000926?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000913?pagingIndex=1&pagingSize=80&productSet=model\n",
      "스킨케어 100000913 34787 434.8375\n",
      "https://search.shopping.naver.com/search/category/100000920?pagingIndex=1&pagingSize=80&productSet=model\n",
      "바디케어 100000920 23068 288.35\n",
      "https://search.shopping.naver.com/search/category/100000921?pagingIndex=1&pagingSize=80&productSet=model\n",
      "헤어케어 100000921 15766 197.075\n",
      "https://search.shopping.naver.com/search/category/100000923?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100001000?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000915?pagingIndex=1&pagingSize=80&productSet=model\n",
      "클렌징 100000915 10065 125.8125\n",
      "https://search.shopping.naver.com/search/category/100000917?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000924?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000918?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000916?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000914?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000919?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100000925?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008296?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008305?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008877?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008299?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100010235?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008298?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008303?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008880?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008881?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008882?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008301?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008302?pagingIndex=1&pagingSize=80&productSet=model\n",
      "https://search.shopping.naver.com/search/category/100008300?pagingIndex=1&pagingSize=80&productSet=model\n"
     ]
    }
   ],
   "source": [
    "CrawlCategoryId(100000003)\n",
    "\n",
    "df, merged_df, attributes = combine_all_category_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71142769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[-1],len(df),df.index[-1]-len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePageDF(category_id, page_id, pagingsize):\n",
    "    url = 'https://search.shopping.naver.com/search/category/' + str(category_id)\n",
    "    params = {\n",
    "        'pagingIndex' : str(page_id),\n",
    "        'pagingSize' : str(pagingsize),\n",
    "        'productSet' : 'model'\n",
    "    }\n",
    "    headers = {'User-Agent': 'Yeti',}\n",
    "    resp = request('GET',url=url, params=params, headers=headers)\n",
    "    print(resp.request.url)\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    script_tag = dom.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "    data = json.loads(script_tag.text)\n",
    "    itemList = data['props']['pageProps']['initialState']['products']\n",
    "    \n",
    "    # 각 상품의 정보를 저장할 리스트를 생성합니다.\n",
    "    products_info = []\n",
    "\n",
    "    for item in itemList['list'][:pagingsize]:\n",
    "\n",
    "        attributes_dict = dict()\n",
    "        # 'attributeValue'와 'characterValue' 문자열을 리스트로 분리합니다.\n",
    "        attribute_values = item['item'].get('attributeValue','').split('|')\n",
    "        character_values = item['item'].get('characterValue','').split('|')\n",
    "\n",
    "        # 'attributeValue' 리스트의 각 요소에서 '_M' 문자열을 제거합니다.\n",
    "        attribute_values = [value.replace('_M', '') for value in attribute_values]\n",
    "\n",
    "        min_len = min(len(attribute_values), len(character_values))\n",
    "\n",
    "        for j in range(min_len):\n",
    "            attribute = attribute_values[j]\n",
    "            character = character_values[j]\n",
    "\n",
    "            if attribute in attributes_dict:\n",
    "                attributes_dict[attribute].append(character)\n",
    "            else:\n",
    "                attributes_dict[attribute] = [character]\n",
    "\n",
    "        attribute_list = [item['item']['category3Name']]\n",
    "\n",
    "        for i in attributes_dict:\n",
    "            if i not in ['용량', '구성', '']:\n",
    "                attribute_list = attribute_list + attributes_dict[i]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        dict_data = {\n",
    "            'ID': item['item']['id'],\n",
    "            '상품명': item['item']['productName'],\n",
    "            '상품 카테고리 대분류': item['item']['category1Name'],\n",
    "            '상품 카테고리 중분류': item['item']['category2Name'],\n",
    "            '상품 카테고리 소분류': item['item']['category3Name'],\n",
    "            '제조사': item['item'].get('maker',''),\n",
    "            '브랜드': item['item'].get('brand',''),\n",
    "            '특징': attribute_list\n",
    "        }\n",
    "        for attribute in attribute_list:\n",
    "            dict_data[attribute] = True\n",
    "\n",
    "        products_info.append(dict_data)\n",
    "\n",
    "    total = data['props']['pageProps']['initialState']['products']['total']\n",
    "    total_page = math.ceil(total/pagingsize)\n",
    "\n",
    "        # 딕셔너리의 리스트를 데이터프레임으로 변환합니다.\n",
    "    df = pd.DataFrame(products_info)\n",
    "    \n",
    "    return df,total_page\n",
    "\n",
    "def makeCategoryDF(category_id):    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for j in [20,40,60,80]:\n",
    "        df,total_page = makePageDF(category_id,1,j)\n",
    "        for i in range(2,total_page+1):\n",
    "            new_df,_ = makePageDF(category_id,i,j)\n",
    "            time.sleep(0.5)\n",
    "            df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    df = df.drop_duplicates(subset=['ID'])\n",
    "    df = pd.DataFrame(df).astype({'제조사': 'category'})\n",
    "    df = pd.DataFrame(df).astype({'브랜드': 'category'})\n",
    "    attribute_columns = df.columns.drop(['ID', '상품명', '상품 카테고리 대분류', '상품 카테고리 중분류','상품 카테고리 소분류','제조사','브랜드','특징'])\n",
    "    df[attribute_columns] = df[attribute_columns].fillna(False).astype('bool')\n",
    "    small_df = df.explode('특징')[['ID','상품명','특징']]\n",
    "    attributes = pd.DataFrame(small_df['특징'].unique()).reset_index()\n",
    "    attributes.columns = ['attribute_id', '특징']\n",
    "    attributes = pd.DataFrame(attributes).astype({'attribute_id': 'category'})\n",
    "    merged_df = pd.merge(small_df, attributes, on=['특징'])\n",
    "    \n",
    "    return df, merged_df, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, merged_df, attributes = makeCategoryDF(100001011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[-1],len(df),df.index[-1]-len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePageDF(category_id, page_id, pagingsize):\n",
    "    url = 'https://search.shopping.naver.com/search/category/' + str(category_id)\n",
    "    params = {\n",
    "        'pagingIndex' : str(page_id),\n",
    "        'pagingSize' : str(pagingsize),\n",
    "        'productSet' : 'model'\n",
    "    }\n",
    "    headers = {'User-Agent': 'Yeti',}\n",
    "    resp = request('GET',url=url, params=params, headers=headers)\n",
    "    print(resp.request.url)\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    script_tag = dom.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "    data = json.loads(script_tag.text)\n",
    "    itemList = data['props']['pageProps']['initialState']['products']\n",
    "    \n",
    "    # 각 상품의 정보를 저장할 리스트를 생성합니다.\n",
    "    products_info = []\n",
    "\n",
    "    for item in itemList['list'][:pagingsize]:\n",
    "\n",
    "        attributes_dict = dict()\n",
    "        # 'attributeValue'와 'characterValue' 문자열을 리스트로 분리합니다.\n",
    "        attribute_values = item['item'].get('attributeValue','').split('|')\n",
    "        character_values = item['item'].get('characterValue','').split('|')\n",
    "\n",
    "        # 'attributeValue' 리스트의 각 요소에서 '_M' 문자열을 제거합니다.\n",
    "        attribute_values = [value.replace('_M', '') for value in attribute_values]\n",
    "\n",
    "        min_len = min(len(attribute_values), len(character_values))\n",
    "\n",
    "        for j in range(min_len):\n",
    "            attribute = attribute_values[j]\n",
    "            character = character_values[j]\n",
    "\n",
    "            if attribute in attributes_dict:\n",
    "                attributes_dict[attribute].append(character)\n",
    "            else:\n",
    "                attributes_dict[attribute] = [character]\n",
    "\n",
    "        attribute_list = [item['item']['category3Name']]\n",
    "\n",
    "        for i in attributes_dict:\n",
    "            if i not in ['용량', '구성', '']:\n",
    "                attribute_list = attribute_list + attributes_dict[i]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        dict_data = {\n",
    "            'ID': item['item']['id'],\n",
    "            '상품명': item['item']['productName'],\n",
    "            '상품 카테고리 대분류': item['item']['category1Name'],\n",
    "            '상품 카테고리 중분류': item['item']['category2Name'],\n",
    "            '상품 카테고리 소분류': item['item']['category3Name'],\n",
    "            '제조사': item['item'].get('maker',''),\n",
    "            '브랜드': item['item'].get('brand',''),\n",
    "            '특징': attribute_list\n",
    "        }\n",
    "        for attribute in attribute_list:\n",
    "            dict_data[attribute] = True\n",
    "\n",
    "        products_info.append(dict_data)\n",
    "\n",
    "    total = data['props']['pageProps']['initialState']['products']['total']\n",
    "    total_page = math.ceil(total/pagingsize)\n",
    "\n",
    "        # 딕셔너리의 리스트를 데이터프레임으로 변환합니다.\n",
    "    df = pd.DataFrame(products_info)\n",
    "    \n",
    "    return df,total_page\n",
    "\n",
    "def makeCategoryDF(category_id):    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for j in [60,80]:\n",
    "        df,total_page = makePageDF(category_id,1,j)\n",
    "        for i in range(2,total_page+1):\n",
    "            new_df,_ = makePageDF(category_id,i,j)\n",
    "            time.sleep(0.3)\n",
    "            df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    df = df.drop_duplicates(subset=['ID'])\n",
    "    df = pd.DataFrame(df).astype({'제조사': 'category'})\n",
    "    df = pd.DataFrame(df).astype({'브랜드': 'category'})\n",
    "    attribute_columns = df.columns.drop(['ID', '상품명', '상품 카테고리 대분류', '상품 카테고리 중분류','상품 카테고리 소분류','제조사','브랜드','특징'])\n",
    "    df[attribute_columns] = df[attribute_columns].fillna(False).astype('bool')\n",
    "    small_df = df.explode('특징')[['ID','상품명','특징']]\n",
    "    attributes = pd.DataFrame(small_df['특징'].unique()).reset_index()\n",
    "    attributes.columns = ['attribute_id', '특징']\n",
    "    attributes = pd.DataFrame(attributes).astype({'attribute_id': 'category'})\n",
    "    merged_df = pd.merge(small_df, attributes, on=['특징'])\n",
    "    \n",
    "    return df, merged_df, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, merged_df, attributes = makeCategoryDF(100001011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[-1],len(df),df.index[-1]-len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ac377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.robotparser import RobotFileParser\n",
    "robot = RobotFileParser('https://shopping.naver.com/robots.txt') # robots.txt 파일을 파싱해서 크롤링 여부를 판단해줌\n",
    "robot.read()\n",
    "robot.can_fetch('Yeti','/search/category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca530b3",
   "metadata": {},
   "source": [
    "# 카테고리 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import time\n",
    "from requests import request\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "resp = request('GET',url=url+Cosmetics_Beauty_Id, headers=headers)\n",
    "print(resp.request.url)\n",
    "\n",
    "dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "script_tag = dom.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "data = json.loads(script_tag.text)\n",
    "\n",
    "title_value_pairs = [{'title': x['title'], 'value': x['value']} for x in data['props']['pageProps']['initialState']['mainFilters'][0]['filterValues']]\n",
    "category_df = pd.DataFrame(title_value_pairs)\n",
    "\n",
    "rows_to_drop = []\n",
    "rows_to_append = []\n",
    "\n",
    "for index, row in category_df.iterrows():\n",
    "    category_url = url + str(row['value'])\n",
    "    time.sleep(0.3)\n",
    "    resp = request('GET',url=category_url,params=params, headers=headers)\n",
    "    print(resp.request.url)\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    script_tag = dom.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "    data = json.loads(script_tag.text)\n",
    "\n",
    "    if data['props']['pageProps']['initialState']['subFilters']:\n",
    "        product_count = data['props']['pageProps']['initialState']['subFilters'][0]['filterValues'][1]['productCount']\n",
    "    else:\n",
    "        product_count = 0\n",
    "\n",
    "\n",
    "    if int(product_count)/int(params['pagingSize']) > 100:\n",
    "        print(row['title'], row['value'], product_count, product_count/int(params['pagingSize']))\n",
    "        rows_to_drop.append(index)\n",
    "        sub_title_value_pairs = [{'title': x['title'], 'value': x['value']} for x in data['props']['pageProps']['initialState']['mainFilters'][0]['filterValues']]\n",
    "        rows_to_append += sub_title_value_pairs\n",
    "\n",
    "# Drop the rows from original DataFrame\n",
    "category_df = category_df.drop(rows_to_drop)\n",
    "\n",
    "# Append new rows to DataFrame\n",
    "category_df = category_df.append(rows_to_append, ignore_index=True)\n",
    "\n",
    "category_df.to_csv('categoryId.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "url = 'https://search.shopping.naver.com/search/category/'\n",
    "params = {\n",
    "    'pagingIndex' : '1',\n",
    "    'pagingSize' : '80',\n",
    "    'productSet' : 'model'\n",
    "}\n",
    "headers = {'User-Agent': 'Yeti',}\n",
    "\n",
    "for index, row in category_df.iterrows():\n",
    "    category_url = url + str(row['value'])\n",
    "    resp = request('GET',url=category_url,params=params, headers=headers)\n",
    "    print(resp.request.url)\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    script_tag = dom.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "    data = json.loads(script_tag.text)\n",
    "\n",
    "\n",
    "    if(product_count/int(params['pagingSize'])>100):\n",
    "        print(row['title'],row['value'],product_count, product_count/int(params['pagingSize']))\n",
    "        title_value_pairs = [{'title': x['title'], 'value': x['value']} for x in data['props']['pageProps']['initialState']['mainFilters'][0]['filterValues']]\n",
    "        sub_category_df = pd.DataFrame(title_value_pairs)\n",
    "\n",
    "#모시우디 는 가격비교가 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb873d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b6301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb565035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c11e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7ebf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7015d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac3d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c056d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MultiSAGE",
   "language": "python",
   "name": "multisage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
